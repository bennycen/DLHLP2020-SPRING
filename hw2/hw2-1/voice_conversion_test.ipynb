{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import cc, Encoder, Decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import VCTK_Dataset\n",
    "from dataset import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "def _run_train(encoder, decoder, criterion, opt, dataloader):\n",
    "        \n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for index, (person, spectrogram) in enumerate(dataloader):\n",
    "        b = person.shape[0]\n",
    "        \n",
    "        opt.zero_grad()\n",
    "    \n",
    "        spectrogram = spectrogram.permute(0,2,1).cuda()\n",
    "        latent = encoder(spectrogram)\n",
    "        person = person.cuda()\n",
    "        output = decoder(latent, person)\n",
    "        \n",
    "        loss = criterion(spectrogram, output)\n",
    "        loss.backward()\n",
    "        \n",
    "        total_loss += loss.item()*b\n",
    "        print(\"\\t [{}/{}] train loss:{:.4f}\".format(index+1,\n",
    "                                              len(dataloader),\n",
    "                                              loss.item()), \n",
    "                                          end='  \\r')\n",
    "        opt.step()\n",
    "        \n",
    "    return total_loss\n",
    "\n",
    "def _run_eval(encoder, decoder, criterion, dataloader):\n",
    "      \n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for index, (person, spectrogram) in enumerate(dataloader):\n",
    "            b = person.shape[0]\n",
    "\n",
    "            spectrogram = spectrogram.permute(0,2,1).cuda()\n",
    "            latent = encoder(spectrogram)\n",
    "            person = person.cuda()\n",
    "            output = decoder(latent, person)\n",
    "\n",
    "            loss = criterion(spectrogram, output)\n",
    "\n",
    "            total_loss += loss.item()*b\n",
    "            print(\"\\t [{}/{}] valid loss:{:.4f}\".format(index+1,\n",
    "                                                  len(dataloader),\n",
    "                                                  loss.item()), \n",
    "                                              end='  \\r')\n",
    "                    \n",
    "    return total_loss\n",
    "    pass\n",
    "\n",
    "def train(args, train_dataloader, valid_dataloader):\n",
    "    \n",
    "    encoder = cc(Encoder())\n",
    "    decoder = cc(Decoder())\n",
    "    \n",
    "    criterion = torch.nn.L1Loss()\n",
    "    opt = torch.optim.Adam(list(encoder.parameters())+list(decoder.parameters()), lr=args.lr)\n",
    "    \n",
    "    for epoch in range(args.epoch):\n",
    "        print(f' Epoch {epoch}')\n",
    "        \n",
    "        loss = _run_train(encoder, decoder, criterion, opt, train_dataloader)\n",
    "        print('\\t [Info] Avg training loss:{:.5f}'.format(loss/len(train_dataloader.dataset)))\n",
    "\n",
    "        loss = _run_eval(encoder, decoder, criterion, valid_dataloader)\n",
    "        print('\\t [Info] Avg valid loss:{:.5f}'.format(loss/len(valid_dataloader.dataset)))\n",
    "        \n",
    "        if True:\n",
    "            save_path = \"{}/epoch_{}_loss_{:.4f}\".format(args.save_path,epoch,loss/len(valid_dataloader.dataset))\n",
    "            torch.save({'state_dict': encoder.state_dict()},\n",
    "                        f\"{save_path}_enc_.pt\")\n",
    "            torch.save({'state_dict': decoder.state_dict()},\n",
    "                        f\"{save_path}_dec_.pt\")\n",
    "            print(f'\\t [Info] save weights at {save_path}')\n",
    "        print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, argparse\n",
    "\n",
    "def parse_args(string=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--lr', default=1e-4,\n",
    "                        type=float, help='leanring rate')\n",
    "    parser.add_argument('--epoch', default=10,\n",
    "                        type=int, help='epochs')\n",
    "    parser.add_argument('--batch-size', default=32,\n",
    "                        type=int, help='batch size')\n",
    "    parser.add_argument('--num-workers', default=6,\n",
    "                        type=int, help='dataloader num workers')\n",
    "    parser.add_argument('--save-path', default='trained_model',\n",
    "                        type=str, help='.pth model file save dir')\n",
    "    \n",
    "    args = parser.parse_args() if string is None else parser.parse_args(string)\n",
    "    if not os.path.exists(args.save_path): os.makedirs(args.save_path)\n",
    "    return args\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    args = parse_args('')\n",
    "    \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = \"0\" #0:1080ti 1:1070\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    ## load dataset\n",
    "    train_dataset = VCTK_Dataset('preprocess/vctk.h5', 'preprocess/sample_segments/train_samples', seg_len=128, mode='train')\n",
    "    valid_dataset = VCTK_Dataset('preprocess/vctk.h5', 'preprocess/sample_segments/valid_samples', seg_len=128, mode='test')\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, \n",
    "                                  batch_size=args.batch_size,\n",
    "                                  #num_workers = args.num_workers,\n",
    "                                  shuffle=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset, \n",
    "                                  batch_size=args.batch_size,)\n",
    "                                  #num_workers = args.num_workers)\n",
    "    \n",
    "    ## train\n",
    "    train(args, train_dataloader, valid_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    person = batch[0][0]\n",
    "    spectrogram = batch[1][0].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.title(f\"person:{person}\")\n",
    "    plt.imshow(spectrogram, cmap=\"hot\")\n",
    "    plt.show()\n",
    "    \n",
    "    input('resume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from preprocess.tacotron.norm_utils import spectrogram2wav, get_spectrograms\n",
    "from scipy.io.wavfile import write\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = cc(Encoder())\n",
    "encoder.load_state_dict(torch.load('trained_model/epoch_7_loss_0.0466_enc_.pt')['state_dict'])\n",
    "decoder = cc(Decoder())\n",
    "decoder.load_state_dict(torch.load('trained_model/epoch_7_loss_0.0466_dec_.pt')['state_dict'])\n",
    "\n",
    "_, spectrogram = get_spectrograms('/media/D/DLHLP/hw2/Corpus/wav48/p2/p2_008.wav')\n",
    "\n",
    "_input = np.expand_dims(spectrogram, axis=0)\n",
    "_input = torch.tensor(_input).permute(0,2,1).cuda()\n",
    "\n",
    "_latent = encoder(_input)\n",
    "\n",
    "person = torch.tensor([0]).cuda()\n",
    "output = decoder(_latent, person)\n",
    "output = output.squeeze(axis=0).transpose(1,0).cpu().detach().numpy()\n",
    "\n",
    "wav_data = spectrogram2wav(output)\n",
    "write('result/abc.wav', 16000, data=wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram.shape, output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(f\"person: 0 \")\n",
    "plt.imshow(spectrogram, cmap=\"hot\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.title(f\"person: 1 \")\n",
    "plt.imshow(output, cmap=\"hot\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from preprocess.tacotron.norm_utils import spectrogram2wav, get_spectrograms\n",
    "from scipy.io.wavfile import write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = cc(Encoder())\n",
    "encoder.load_state_dict(torch.load('trained_model/epoch_7_loss_0.0466_enc_.pt')['state_dict'])\n",
    "decoder = cc(Decoder())\n",
    "decoder.load_state_dict(torch.load('trained_model/epoch_7_loss_0.0466_dec_.pt')['state_dict'])\n",
    "\n",
    "_, spectrogram = get_spectrograms('/media/D/DLHLP/hw2/Corpus/wav48/p1/p1_334.wav')\n",
    "\n",
    "_input = np.expand_dims(spectrogram, axis=0)\n",
    "_input = torch.tensor(_input).permute(0,2,1).cuda()\n",
    "\n",
    "_latent = encoder(_input)\n",
    "\n",
    "p1 = torch.tensor([0]).cuda()\n",
    "p2 = torch.tensor([1]).cuda()\n",
    "output = decoder.interpolate(_latent, p1, p2)\n",
    "#output = decoder(_latent, p1)\n",
    "output = output.squeeze(axis=0).transpose(1,0).cpu().detach().numpy()\n",
    "\n",
    "wav_data = spectrogram2wav(output)\n",
    "write('result/abc.wav', 16000, data=wav_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
